{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install the required packages",
   "id": "522a01da1699b6ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow_datasets\n",
    "!pip install numpy\n",
    "!pip install tensorflow-model-optimization\n",
    "!pip install tf_keras"
   ],
   "id": "322ce374b236db71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the required libraries",
   "id": "fcc6338e1a470057"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot"
   ],
   "id": "d4d28b656b14e44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the EMNIST 'byclass' dataset",
   "id": "70e7ee6511b2e496"
  },
  {
   "cell_type": "code",
   "id": "b6e9863deacc036d",
   "metadata": {},
   "source": [
    "(train_ds, test_ds), info = tfds.load(\n",
    "    'emnist/byclass',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "original_class_names = info.features['label'].names"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "dIn EMNIST byclass:<br>\n",
    "0-9 are digits<br>\n",
    "10-35 are uppercase letters A-Z<br>\n",
    "36-61 are lowercase letters a-z<br>\n",
    "\n",
    "Define the range of labels for uppercase letters"
   ],
   "id": "3f98c0c0b77c241"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LABELS_TO_KEEP_START_INDEX = 10 # Corresponds to 'A'\n",
    "LABELS_TO_KEEP_END_INDEX = 35  # Corresponds to 'Z'\n",
    "NUM_CLASSES_TO_TRAIN = (LABELS_TO_KEEP_END_INDEX - LABELS_TO_KEEP_START_INDEX) + 1 # Should be 26\n",
    "\n",
    "def filter_uppercase(_, label):\n",
    "    is_uppercase = tf.logical_and(\n",
    "        tf.greater_equal(label, LABELS_TO_KEEP_START_INDEX),\n",
    "        tf.less_equal(label, LABELS_TO_KEEP_END_INDEX)\n",
    "    )\n",
    "    return is_uppercase\n",
    "\n",
    "def remap_label_to_zero_indexed(image, label):\n",
    "    new_label = label - LABELS_TO_KEEP_START_INDEX\n",
    "    return image, new_label\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.rot90(image, k=-1)\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_batches = train_ds.filter(filter_uppercase).map(remap_label_to_zero_indexed).map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_batches = test_ds.filter(filter_uppercase).map(remap_label_to_zero_indexed).map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ],
   "id": "45d69afece45575d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Define the Base Keras Model (Non-Quantized)<br>\n",
    "Perhaps add BatchNormalization for better quantization stability?<br>"
   ],
   "id": "709ba370e249b4b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'), # Reduced filters\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'), # Reduced filters\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'), # Reduced dense layer size\n",
    "    tf.keras.layers.Dropout(0.3), # Keep dropout for regularization\n",
    "    tf.keras.layers.Dense(NUM_CLASSES_TO_TRAIN, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"\\n--- Base Keras Model Summary (Before QAT) ---\")\n",
    "base_model.summary()"
   ],
   "id": "e72bb141ae2e030",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Apply Quantization-Aware Training Wrappers<br>\n",
    "This step wraps the layers of the base_model with quantization operations.<br>"
   ],
   "id": "4a1337da4e2b627d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(base_model)"
   ],
   "id": "f001db22922c3634",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compile the Quantization-Aware Model",
   "id": "e9cc5fd6ffe8097c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q_aware_model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "print(\"\\n--- Quantization-Aware Model Summary (During Training) ---\")\n",
    "q_aware_model.summary()"
   ],
   "id": "acba8169a8e26555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Define an EarlyStopping Callback<br>\n",
    "Stop training when validation accuracy reaches 97.5% (0.975) or more. Or when there's been no improvement for at least 20 epochs.<br>\n",
    "Restore model weights from the best epoch."
   ],
   "id": "c3d39147cf8f7664"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    baseline=0.976,\n",
    "    restore_best_weights=True\n",
    ")"
   ],
   "id": "3e6ae3fa7c8374d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Define different weights for problematic classes. If the model tends to favour certain characters, over visually similar ones, this can be remediated by lowering its weight below 1.0.<br>\n",
    "The opposite is also true, if the model tends to ignore certain characters, their weight can be increased above 1.0. Up to 3.0<br>\n",
    "The different weights are estimations based on manual testing on the actual device - an ESP32 with a Cirque trackpad.<br>"
   ],
   "id": "b3f5d9408d3663e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_weight = {i: 1.0 for i in range(NUM_CLASSES_TO_TRAIN)}\n",
    "class_weight[1] = 0.8  # \"B\"\n",
    "class_weight[2] = 3.0  # \"C\"\n",
    "class_weight[4] = 2.6  # \"E\"\n",
    "class_weight[6] = 1.5  # \"G\"\n",
    "class_weight[8] = 3.0  # \"I\"\n",
    "class_weight[9] = 2.8  # \"J\"\n",
    "class_weight[14] = 2.0  # \"O\"\n",
    "class_weight[15] = 1.7  # \"P\"\n",
    "class_weight[16] = 0.08  # \"Q\"\n",
    "class_weight[17] = 1.5  # \"R\"\n",
    "class_weight[18] = 2.0  # \"S\"\n",
    "class_weight[24] = 2.0 # \"Y\"\n",
    "class_weight[25] = 2.2 # \"Z\""
   ],
   "id": "8581a3692feadd1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Train the Quantization-Aware Model with the Callback<br>\n",
    "Training will run for 50 epochs or until the early stopping condition is met.<br>\n",
    "<br>\n",
    "_Note that warnings such as: \"Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\" are to be expected with certain Tensorflow versions. They are harmless._"
   ],
   "id": "59d7859e45871d20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"\\n--- Training QAT Model (Stopping at val_accuracy >= {early_stopping_callback.baseline}) ---\")\n",
    "history = q_aware_model.fit(\n",
    "    train_batches,\n",
    "    epochs=50,\n",
    "    validation_data=test_batches,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    class_weight=class_weight\n",
    ")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the Quantization-Aware Model",
   "id": "42365b4d4f92711e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss, accuracy = q_aware_model.evaluate(test_batches)\n",
    "print(f\"\\n--- Quantization-Aware Model Evaluation (Keras, Float Sim) ---\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ],
   "id": "fe3825577519698e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Convert the Quantization-Aware Model to LiteRT (.tflite) with FLOAT16 weights<br>\n",
    "Input and output are still float32 (0.0-1.0)<br>"
   ],
   "id": "15a900ccbc66d10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "converter_qat = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter_qat.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter_qat.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "converter_qat.inference_input_type = tf.float32\n",
    "converter_qat.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model_qat_float16 = converter_qat.convert()"
   ],
   "id": "de6778f09acada01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the Quantization-Aware TFLite model (Float16 weights)<br>",
   "id": "70a508a6b815ddfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "qat_float16_model_path = '.workdir/emnist_uppercase_qat_float16_model.tflite'\n",
    "with open(qat_float16_model_path, 'wb') as f:\n",
    "    f.write(tflite_model_qat_float16)\n",
    "\n",
    "print(f\"\\nQuantization-Aware TFLite model (Float16 weights) saved to: {qat_float16_model_path}\")"
   ],
   "id": "90149c0add976991",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the Float16 Quantized LiteRT Model",
   "id": "9c706f4d498965ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_qat_float16)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "quant_test_accuracy = 0\n",
    "num_test_samples = 0\n",
    "\n",
    "for images, labels in test_batches:\n",
    "    for i in range(images.shape[0]):\n",
    "        input_data = images[i:i+1]\n",
    "        true_label = labels[i]\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        predicted_label = np.argmax(output[0])\n",
    "\n",
    "        if predicted_label == true_label:\n",
    "            quant_test_accuracy += 1\n",
    "        num_test_samples += 1\n",
    "\n",
    "final_quant_accuracy = quant_test_accuracy / num_test_samples\n",
    "print(f\"\\n--- QAT TFLite Model Evaluation (Python Interpreter, Float16 Weights) ---\")\n",
    "print(f\"Test Accuracy: {final_quant_accuracy:.4f}\")"
   ],
   "id": "55a70f7d997f70c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the Quantization-Aware TFLite model as a C array<br>",
   "id": "30ed3383cc9d77c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(qat_float16_model_path, 'rb') as f:\n",
    "    tflite_model = f.read()\n",
    "\n",
    "c_array_name = 'emnist_uppercase_model_qat_float16'\n",
    "c_array_code = f\"const unsigned char {c_array_name}[] = {{\\n\"\n",
    "c_array_code += ', '.join([f'0x{byte:02x}' for byte in tflite_model])\n",
    "c_array_code += '\\n};'\n",
    "\n",
    "output_file = '../include/emnist_uppercase_model_qat_float16.h'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(c_array_code)\n",
    "\n",
    "print(f\"QAT Float16 model converted to C array and saved as {output_file}\")"
   ],
   "id": "afc8513265b45c48",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
